{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, date\n",
    "\n",
    "filePath = '../../'\n",
    "\n",
    "url = 'http://espn.go.com/nhl/teams'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text)\n",
    "tables = soup.find_all('ul', class_='medium-logos')\n",
    "teams = []\n",
    "prefix_1 = []\n",
    "prefix_2 = []\n",
    "teams_urls = []\n",
    "for table in tables:\n",
    "    lis = table.find_all('li')\n",
    "    for li in lis:\n",
    "        info = li.h5.a\n",
    "        teams.append(info.text)\n",
    "        url = info['href']\n",
    "        teams_urls.append(url)\n",
    "        prefix_1.append(url.split('/')[-2])\n",
    "        prefix_2.append(url.split('/')[-1])\n",
    "\n",
    "\n",
    "dic = {'url': teams_urls, 'prefix_2': prefix_2, 'prefix_1': prefix_1}\n",
    "teams = pd.DataFrame(dic, index=teams)\n",
    "teams.index.name = 'team'\n",
    "#print(teams)\n",
    "teams.to_csv(\"NHL teams.csv\")\n",
    "\n",
    "\n",
    "# In[96]:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, date\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def rec_replace(string, a, b):\n",
    "    if not string: #if the string is empty\n",
    "        return \"\"\n",
    "    elif string[:len(b)] == b: #if the string start with b, replace it with a\n",
    "        return a + rec_replace(string[len(b):], a, b)\n",
    "    else: #else, add this character and go to the next one\n",
    "        return string[0] + rec_replace(string[1:], a, b)\n",
    "    \n",
    "filepath = '../..'\n",
    "year = 2016\n",
    "seasonType=1 #preseason\n",
    "teams = pd.read_csv('NHL teams.csv')\n",
    "BASE_URL_sched = 'http://espn.go.com/nhl/team/schedule/_/name/{0}/{1}'\n",
    "\n",
    "visitTeam=[]\n",
    "homeTeam=[]\n",
    "gameType=[]\n",
    "homeAway=[]\n",
    "gameDate=[]\n",
    "gameTime=[]\n",
    "gameDOW=[]\n",
    "gameDMY=[]\n",
    "venue=[]\n",
    "fullName=[]\n",
    "\n",
    "for index, row in teams.iterrows():\n",
    "    _team, url = row['team'], row['url']\n",
    "    r = requests.get(BASE_URL_sched.format(row['prefix_1'],seasonType,row['prefix_2']))\n",
    "    #print BASE_URL.format(row['prefix_1'], year,seasonType, row['prefix_2'])\n",
    "    table = BeautifulSoup(r.text)\n",
    "    for row in table.find_all('tr')[0:]: # Remove header\n",
    "        columns = row.find_all('td')\n",
    "        if columns[0].text == \"2016 Preseason Schedule\":\n",
    "            preseason = \"Preseason\"\n",
    "        elif columns[0].text == \"2016 Regular Season Schedule\":\n",
    "            preseason = \"Regular Season\"\n",
    "        else:\n",
    "            preseason = preseason\n",
    "    \n",
    "        try:\n",
    "            gameDate=columns[0].text.split(', ')[1]\n",
    "            gameDate=str(re.sub('-',' ',gameDate))\n",
    "            gameDMY.append(gameDate)\n",
    "            gameType.append(preseason)\n",
    "            gameDOW.append(columns[0].text.split(', ')[0])\n",
    "            if re.search(r'\\w{3}\\s\\d',gameDate):\n",
    "                teamName= columns[1].a['href'].split('/')[-1]\n",
    "                teamName=re.sub('-',' ',teamName).title()\n",
    "                gameTime= columns[2].text\n",
    "                if columns[1].text[0]==\"@\":\n",
    "                    visitTeam.append(_team)\n",
    "                    homeTeam.append(teamName)\n",
    "                else:\n",
    "                    homeTeam.append(_team)\n",
    "                    visitTeam.append(teamName)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "dic = {'Game_Type':gameType,'Home_Team':homeTeam,'Visit_Team':visitTeam, 'Game_Day':gameDOW,'Game_Date':gameDMY, 'Game_Time': gameTime, 'Game_Date': gameDMY}\n",
    "\n",
    "print len(homeTeam),len(visitTeam),len(gameDOW)\n",
    "NHLgames = pd.DataFrame(dic)#.drop_duplicates(cols='id').set_index('id')\n",
    "NHLgames=NHLgames.drop_duplicates()\n",
    "NHLgames.to_csv(\"NHL games 2016.csv\", sep=',')\n",
    "     \n",
    "\n",
    "\n",
    "# In[117]:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, date\n",
    "from googleplaces import GooglePlaces, types, lang\n",
    "\n",
    "#MY_API_KEY = 'AIzaSyAzOt8cn7TkD1LxAH_giuyd6AgF5IHDCiw'\n",
    "geocode_URL = 'https://maps.googleapis.com/maps/api/geocode/json?address={0}&key=AIzaSyAzOt8cn7TkD1LxAH_giuyd6AgF5IHDCiw'\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def rec_replace(string, a, b):\n",
    "    if not string: #if the string is empty\n",
    "        return \"\"\n",
    "    elif string[:len(b)] == b: #if the string start with b, replace it with a\n",
    "        return a + rec_replace(string[len(b):], a, b)\n",
    "    else: #else, add this character and go to the next one\n",
    "        return string[0] + rec_replace(string[1:], a, b)\n",
    "    \n",
    "filepath = '../..'\n",
    "year = 2016\n",
    "seasonType=1 #preseason\n",
    "teams = pd.read_csv('NHL teams.csv')\n",
    "BASE_URL_stad = 'http://espn.go.com/nhl/team/stadium/_/name/{0}/{1}'\n",
    "\n",
    "venue=[]\n",
    "homeTeam=[]\n",
    "streetAddress=[]\n",
    "city=[]\n",
    "state=[]\n",
    "zipcode=[]\n",
    "lat=[]\n",
    "lon=[]\n",
    "\n",
    "for index, row in teams.iterrows():\n",
    "    _team, url = row['team'], row['url']\n",
    "    r = requests.get(BASE_URL_stad.format(row['prefix_1'],row['prefix_2']))\n",
    "    #print BASE_URL_stad.format(row['prefix_1'], row['prefix_2'])\n",
    "    table = BeautifulSoup(r.text)\n",
    "    for row in table.find_all('span')[0:1]: # Remove header\n",
    "        rawText=unicode(row)\n",
    "        rawText= re.sub('<span>', '', rawText)\n",
    "        rawText= re.sub('</span>', '', rawText)\n",
    "        nonStreetAddress= rawText.split('<br/>')[1]\n",
    "        streetAddress.append(rawText.split('<br/>')[0])\n",
    "        city.append(nonStreetAddress.split(', ')[0])\n",
    "        state.append(nonStreetAddress.split(', ')[1].split(' ')[0])\n",
    "        if _team =='Montreal Canadiens':\n",
    "            zipcode.append(\"NA\")\n",
    "        else:\n",
    "             zipcode.append(nonStreetAddress.split(', ')[1].split(' ')[1])\n",
    "            \n",
    "        homeTeam.append(_team)\n",
    "        \n",
    "        _geocodeAdd=rawText.split('<br/>')[0]+' '+rawText.split('<br/>')[1]\n",
    "        geocode_req=requests.get(geocode_URL.format(_geocodeAdd))\n",
    "        geocode_raw=json.loads(geocode_req.text)\n",
    "        _lat= (geocode_raw['results'][0]['geometry']['location']['lat'])\n",
    "        _lon=(geocode_raw['results'][0]['geometry']['location']['lng'])\n",
    "        lat.append(_lat)\n",
    "        lon.append(_lon)\n",
    "    for tag in table.find_all('h2')[1:]:\n",
    "        venue.append(tag.text)\n",
    "        \n",
    "dic = {'Home_Team':homeTeam,'Venue':venue,'Street_Address':streetAddress, 'City': city , 'State': state,'Zipcode':zipcode,'Lat': lat,'Lon':lon}\n",
    "NHLvenues = pd.DataFrame(dic)#.drop_duplicates(cols='id').set_index('id')\n",
    "NHLvenues.to_csv(\"NHL venue locations.csv\", sep=',')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
